# ------------------------------- Imports -------------------------------

import os                         # Provides tools for interacting with the operating system (folders/files)
from PIL import Image             # Imports PIL Image for opening and converting image files
import torch                      # Imports PyTorch core library for tensors and GPU support
import torch.nn as nn             # Imports neural network layers/modules (e.g., Linear, ReLU, Dropout)
import torch.optim as optim       # Imports optimizers and learning-rate schedulers

from torch.utils.data import Dataset, DataLoader, random_split   # Dataset base class, DataLoader, and dataset splitting utility
import torchvision.transforms as transforms                      # Common image preprocessing and augmentation transforms
from torchvision.models import resnet18, ResNet18_Weights        # Pretrained ResNet-18 model and its weight enums
from timm.models.vision_transformer import vit_base_patch16_224  # Pretrained Vision Transformer (ViT-B/16) from timm

# ------------------------------- Device configuration -------------------------------

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available, otherwise CPU

# ------------------------------- Hyperparameters and constants -------------------------------
num_classes = 4          # Number of emotion categories (Updated to 4 based on available folders)
batch_size = 32          # Number of samples per mini-batch
learning_rate = 5e-5     # Learning rate (small for stable fine-tuning, especially for ViT)
num_epochs = 25          # Maximum number of training epochs (early stopping can stop sooner)
image_size = 224         # Input image size required by ResNet-18 and ViT-B/16

# ------------------------------- Class order (explicit mapping) -------------------------------
FERAC_CLASSES = ["anger", "fear", "joy", "Natural"]  # Fixed label order matching actual folder names

# ------------------------------- Image transforms -------------------------------
transform = transforms.Compose([                                     # Chain multiple transforms into one pipeline
    transforms.Resize((image_size, image_size)),                     # Resize images to 224x224 for consistent input size
    transforms.RandomHorizontalFlip(p=0.5),                          # Randomly flip image horizontally (50% chance)
    transforms.RandomRotation(10),                                   # Randomly rotate image up to +/- 10 degrees
    transforms.RandomApply(                                          # Apply the following transform(s) only with probability p
        [transforms.ColorJitter(0.2, 0.2, 0.2, 0.1)],                # Randomly change brightness/contrast/saturation/hue
        p=0.7                                                        # Apply ColorJitter with 70% probability
    ),
    transforms.RandomGrayscale(p=0.1),                               # Convert image to grayscale with 10% probability
    transforms.ToTensor(),                                           # Convert PIL image to PyTorch tensor (C x H x W)
    transforms.Normalize(mean=[0.485, 0.456, 0.406],                 # Normalize using ImageNet mean (per channel)
                         std=[0.229, 0.224, 0.225])                  # Normalize using ImageNet std (per channel)
])

# ------------------------------- Custom Dataset class -------------------------------
class FERACDataset(Dataset):                                         # Define a custom dataset class inheriting from torch Dataset
    def __init__(self, root_dir, transform=None):                    # Constructor: takes dataset root folder and transform pipeline
        self.root_dir = root_dir                                     # Store root directory path (e.g., "./consolidated")
        self.transform = transform                                   # Store transforms to apply to each loaded image
        self.samples = []                                            # Initialize empty list to store (filepath, label) pairs

        self.classes = FERAC_CLASSES                                 # Use fixed class list to enforce consistent labels
        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}  # Map class name -> numeric index

        # Iterate through 'train' and 'test' subdirectories
        for subset_name in ['train', 'test']:
            subset_dir = os.path.join(root_dir, subset_name)
            if not os.path.isdir(subset_dir):
                print(f"Warning: Missing subset folder: {subset_dir}. Skipping.")
                continue

            for cls_name in self.classes:                                # Loop through each class folder (angry, disgust, ...)
                cls_dir = os.path.join(subset_dir, cls_name)               # Build full folder path for the class
                if not os.path.isdir(cls_dir):                           # Check that the class folder exists
                    raise FileNotFoundError(f"Missing class folder: {cls_dir}")  # Raise error if folder is missing (prevents silent bugs)

                for fname in os.listdir(cls_dir):                        # Iterate over all files inside the class folder
                    fpath = os.path.join(cls_dir, fname)                 # Build full file path for the current file
                    if os.path.isfile(fpath) and fname.lower().endswith(('.png', '.jpg', '.jpeg')):  # Keep only image files
                        self.samples.append((fpath, self.class_to_idx[cls_name]))  # Add (path, label) to sample list

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, label

# ------------------------------- Dataset loading and splitting -------------------------------
dataset_path = './FERAC Dataset'                                     # Root folder containing FERAC class subfolders
full_dataset = FERACDataset(root_dir=dataset_path, transform=transform)  # Create dataset instance with transforms

total_size = len(full_dataset)                                       # Total number of images in dataset
train_size = int(0.7 * total_size)                                   # Compute training set size (70%)
val_size = int(0.15 * total_size)                                    # Compute validation set size (15%)
test_size = total_size - train_size - val_size                       # Assign remaining images to test set (ensures exact total)

train_dataset, val_dataset, test_dataset = random_split(             # Split full dataset into train/val/test subsets
    full_dataset,                                                   # Dataset to be split
    [train_size, val_size, test_size],
    generator=torch.Generator().manual_seed(42)                      # Fix seed to make the split reproducible
)

train_loader = DataLoader(train_dataset, batch_size=batch_size,      # DataLoader for training subset
                          shuffle=True, num_workers=4,              # Shuffle training data and load in parallel with 4 workers
                          pin_memory=True, persistent_workers=True) # Speed up GPU transfer + keep workers alive

val_loader = DataLoader(val_dataset, batch_size=batch_size,          # DataLoader for validation subset
                        shuffle=False, num_workers=4,                # No shuffle for validation
                        pin_memory=True, persistent_workers=True)    # Same performance settings

test_loader = DataLoader(test_dataset, batch_size=batch_size,        # DataLoader for test subset
                         shuffle=False, num_workers=4,               # No shuffle for test evaluation
                         pin_memory=True, persistent_workers=True)   # Same performance settings

# ------------------------------- Hybrid CNNâ€“ViT model definition -------------------------------
class FER_ViT(nn.Module):                                            # Define hybrid model class inheriting from nn.Module
    def __init__(self, num_classes=num_classes):                     # Constructor: takes number of classes (7)
        super(FER_ViT, self).__init__()                               # Initialize parent nn.Module

        self.backbone = resnet18(weights=ResNet18_Weights.DEFAULT)    # Load ResNet-18 pretrained on ImageNet
        self.backbone.fc = nn.Identity()                              # Replace final FC layer with Identity -> output is 512-d feature vector

        self.vit = vit_base_patch16_224(pretrained=True)              # Load ViT-B/16 pretrained (outputs 768-d embeddings)

        for name, param in self.backbone.named_parameters():          # Loop over ResNet parameters with names
            param.requires_grad = False                               # Freeze all ResNet layers by default
            if 'layer3' in name or 'layer4' in name:                  # If parameter belongs to deeper layers
                param.requires_grad = True                            # Unfreeze layer3 and layer4 for fine-tuning

        for param in self.vit.parameters():                           # Loop through all ViT parameters
            param.requires_grad = True                                # Enable training for all ViT parameters

        self.feature_fusion = nn.Sequential(                          # Define fusion module as a sequential stack
            nn.Linear(512 + 768, 512),                                # Project concatenated features (1280) down to 512
            nn.BatchNorm1d(512),                                      # BatchNorm for stable feature scaling
            nn.ReLU()                                                 # ReLU activation to add nonlinearity
        )

        self.classifier = nn.Sequential(                              # Define classifier head as a sequential stack
            nn.Dropout(0.4),                                          # Dropout to reduce overfitting during training
            nn.Linear(512, num_classes)                               # Final linear layer producing logits for 7 classes
        )

    def forward(self, x):                                             # Forward pass: defines how input flows through the model
        local_features = self.backbone(x)                             # ResNet extracts local features -> shape (B, 512)

        vit_out = self.vit.forward_features(x)                        # Extract ViT features (shape may vary by timm version)
        if vit_out.ndim == 3:                                         # If output has tokens dimension: (B, T, 768)
            vit_class_token = vit_out[:, 0, :]                        # Take CLS token -> (B, 768)
        else:                                                         # Otherwise output is already pooled: (B, 768)
            vit_class_token = vit_out                                 # Use it directly as global feature vector

        combined_features = torch.cat((local_features, vit_class_token), dim=1)  # Concatenate -> (B, 1280)
        fused = self.feature_fusion(combined_features)                # Apply fusion module -> (B, 512)
        out = self.classifier(fused)                                  # Apply classifier -> logits (B, 7)
        return out                                                    # Return logits for cross-entropy loss

# ------------------------------- Instantiate model, loss, optimizer, scheduler -------------------------------
model = FER_ViT().to(device)                                          # Create model instance and move it to GPU/CPU device

criterion = nn.CrossEntropyLoss()                                     # Loss for multi-class classification using logits + integer labels

optimizer = optim.Adam(                                               # Create Adam optimizer
    filter(lambda p: p.requires_grad, model.parameters()),            # Only optimize parameters that are trainable
    lr=learning_rate                                                  # Set learning rate
)

scheduler = optim.lr_scheduler.ReduceLROnPlateau(                     # Scheduler that reduces LR when val loss plateaus
    optimizer,                                                        # Optimizer to adjust
    mode='min',                                                       # Reduce LR when validation loss stops decreasing
    factor=0.5,                                                       # Multiply LR by 0.5 when plateau detected
    patience=2                                                        # Wait 2 epochs with no improvement before reducing LR
)

# ------------------------------- Training, validation, and test functions -------------------------------
def train():                                                          # Define one full training epoch
    model.train()                                                     # Set model to training mode (enables dropout, BN updates)
    total_loss, correct, total = 0.0, 0, 0                            # Track total loss, correct predictions, total samples

    for images, labels in train_loader:                               # Loop over all training batches
        images, labels = images.to(device), labels.to(device)         # Move batch tensors to GPU/CPU

        outputs = model(images)                                       # Forward pass: compute logits
        loss = criterion(outputs, labels)                             # Compute cross-entropy loss

        optimizer.zero_grad()                                         # Clear previous gradients
        loss.backward()                                               # Backpropagate to compute new gradients
        optimizer.step()                                              # Update trainable parameters

        total_loss += loss.item() * images.size(0)                    # Accumulate loss weighted by batch size
        predicted = outputs.argmax(1)                                 # Predicted class indices from logits
        total += labels.size(0)                                       # Update number of processed samples
        correct += predicted.eq(labels).sum().item()                  # Count correct predictions in this batch

    avg_loss = total_loss / total                                     # Compute average loss over all samples
    accuracy = 100.0 * correct / total                                # Compute accuracy percentage
    return avg_loss, accuracy                                         # Return epoch loss and accuracy


def validate():                                                       # Define validation evaluation (no training)
    model.eval()                                                      # Set model to evaluation mode (disables dropout, fixes BN)
    total_loss, correct, total = 0.0, 0, 0                            # Track validation loss and accuracy stats

    with torch.no_grad():                                             # Disable gradient computation for speed/memory savings
        for images, labels in val_loader:                             # Loop over validation batches
            images, labels = images.to(device), labels.to(device)     # Move batch tensors to GPU/CPU

            outputs = model(images)                                   # Forward pass
            loss = criterion(outputs, labels)                         # Compute loss

            total_loss += loss.item() * images.size(0)                # Accumulate loss
            predicted = outputs.argmax(1)                             # Get predicted labels
            total += labels.size(0)                                   # Update total count
            correct += predicted.eq(labels).sum().item()              # Update correct predictions

    avg_loss = total_loss / total                                     # Compute mean validation loss
    accuracy = 100.0 * correct / total                                # Compute validation accuracy
    return avg_loss, accuracy                                         # Return validation loss and accuracy


def test():                                                           # Define final test evaluation
    model.eval()                                                      # Set evaluation mode
    total_loss, correct, total = 0.0, 0, 0                            # Track test loss and accuracy

    with torch.no_grad():                                             # Disable gradients
        for images, labels in test_loader:                            # Loop over test batches
            images, labels = images.to(device), labels.to(device)     # Move batch to device

            outputs = model(images)                                   # Forward pass
            loss = criterion(outputs, labels)                         # Compute loss

            total_loss += loss.item() * images.size(0)                # Accumulate test loss
            predicted = outputs.argmax(1)                             # Predicted class indices
            total += labels.size(0)                                   # Total test samples processed
            correct += predicted.eq(labels).sum().item()              # Count correct predictions

    avg_loss = total_loss / total                                     # Mean test loss
    accuracy = 100.0 * correct / total                                # Test accuracy percentage
    return avg_loss, accuracy                                         # Return test loss and accuracy

# ------------------------------- Training loop with early stopping -------------------------------
patience = 10                                                         # Number of epochs to wait with no improvement before stopping
best_val_loss = float('inf')                                          # Initialize best validation loss to infinity
best_val_acc = 0.0                                                    # Track validation accuracy at best loss
best_epoch = -1                                                       # Track which epoch produced best loss
epochs_no_improve = 0                                                 # Counter for consecutive epochs without improvement

for epoch in range(num_epochs):
    train_loss, train_acc = train()
    val_loss, val_acc = validate()

    scheduler.step(val_loss)

    if val_loss < best_val_loss - 1e-4:
        best_val_loss = val_loss
        best_val_acc = val_acc
        best_epoch = epoch + 1
        epochs_no_improve = 0
        torch.save(model.state_dict(), 'fer_vit_best.pth')
    else:
        epochs_no_improve += 1

    print(f"Epoch [{epoch+1}/{num_epochs}] "
          f"Train Loss: {train_loss:.4f} Train Acc: {train_acc:.2f}% "
          f"Val Loss: {val_loss:.4f} Val Acc: {val_acc:.2f}% "
          f"(no improve: {epochs_no_improve})")

    if epochs_no_improve >= patience:
        print(f"\nEarly stopping triggered at epoch {epoch+1}")
        break

print(f"\nBest validation loss: {best_val_loss:.4f} "
      f"Best validation accuracy: {best_val_acc:.2f}% at epoch {best_epoch}")

# ------------------------------- Final test evaluation using best model -------------------------------
model.load_state_dict(torch.load('fer_vit_best.pth', map_location=device))
test_loss, test_acc = test()
print(f"Test Loss: {test_loss:.4f} Test Acc: {test_acc:.2f}%")
